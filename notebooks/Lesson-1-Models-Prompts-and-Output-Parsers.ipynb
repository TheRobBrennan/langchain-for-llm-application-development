{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Models, Prompts, and Output Parsers\n",
    "\n",
    "Create an OpenAI API key for this project at [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys). \n",
    "\n",
    "Copy `.env.sample` to `.env` and replace `<YOUR_OPENAI_API_KEY>` with the one you created.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin working with Python, let's install the following dependencies from the command-line of our Python virtual environment:\n",
    "\n",
    "```sh\n",
    "(.venv) % pip install python-dotenv\n",
    "(.venv) % pip install openai\n",
    "```\n",
    "\n",
    "Save the newly installed dependencies to `requirements.txt`:\n",
    "\n",
    "```sh\n",
    "(.venv) % pip freeze > requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we can read our OpenAI key from the `.env` file we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the gpt-3.5-turbo-1106\n",
    "llm_model=\"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API : OpenAI\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ The SDK was rewritten in v1 - which means running these examples after November 6th, 2023 needs a migration.\n",
    "\n",
    "Thankfully, there is a [v1.0.0 Migration Guide](https://github.com/openai/openai-python/discussions/742) available at [https://github.com/openai/openai-python/discussions/742](https://github.com/openai/openai-python/discussions/742)\n",
    "\n",
    "TL;DR\n",
    "```sh\n",
    "(.venv) % pip install --upgrade openai\n",
    "(.venv) % pip freeze > requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the OpenAI SDK upgrade complete, we can now define our OpenAI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an example chat completion to make sure we have the updated syntax correct before resuming the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the `os` module in Python to achieve this. Here's an example of how to output all files in a directory using Python:\n",
      "\n",
      "```python\n",
      "import os\n",
      "\n",
      "# Replace 'directory_path' with the path of the directory you want to list the files from\n",
      "directory_path = '/path/to/your/directory'\n",
      "\n",
      "# Get a list of all files in the directory\n",
      "files = os.listdir(directory_path)\n",
      "\n",
      "# Output the list of files\n",
      "for file in files:\n",
      "    print(file)\n",
      "```\n",
      "\n",
      "This code uses the `listdir` function from the `os` module to get a list of all files in the specified directory, and then it prints each file name to the console.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Assuming your API key is set in your environment variables as OPENAI_API_KEY\n",
    "# If not, you can set it in your script (not recommended for production code):\n",
    "# openai.api_key = 'your-api-key'\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model=llm_model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do I output all files in a directory using Python?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see about trying the example chat completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1 is equal to 2.\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(\n",
    "    model=llm_model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is 1+1?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
